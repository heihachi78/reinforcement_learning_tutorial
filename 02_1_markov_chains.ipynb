{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Part 2.1: Transition Matrices and Markov Chains\n\nWelcome to Part 2.1 of our Reinforcement Learning tutorial series! This notebook introduces the mathematical foundations we'll need to understand MDPs - starting with the most fundamental building block: transition matrices and Markov chains.\n\n## Recap from Part 1\n\nIn Part 1 (Foundations of RL), we covered:\n- The agent-environment interaction loop and how RL agents learn through trial and error\n- The Markov property: the future depends only on the present state, not the full history\n- Value functions V(s) and Q(s,a) that quantify how \"good\" states and actions are\n- The discount factor \u03b3 that makes sooner rewards more valuable than distant ones\n- Models of the environment (transitions P and rewards R) vs model-free learning\n\n## Preview\n\nNow we'll formalize these concepts mathematically. We start with **transition matrices** - the mathematical representation of \"where can I go from here?\" This foundation will lead us through Markov Reward Processes (Part 2.2) to full Markov Decision Processes (Part 2.3), building up the complete mathematical framework for RL.\n\n## What This Notebook Covers\n- Transition probability matrices and how they describe state evolution\n- Markov processes (Markov chains) and the Markov property\n- Simulating random walks on Markov chains\n- Building transition matrices from environments like FrozenLake\n\n## What This Notebook Does NOT Cover\n\n| Topic | Why Not Here | How It Differs From What We Cover |\n|-------|--------------|-----------------------------------|\n| **Rewards** | Markov chains model state evolution only. Rewards come in Part 2.2 (MRPs). | We focus on *where you can go* (transitions between states). MRPs add *how valuable each state is* (rewards), letting us evaluate \"good\" vs \"bad\" states. |\n| **Actions and decision-making** | Markov chains have no actions - transitions happen automatically. Actions come in Part 2.3 (MDPs). | Here, state evolution is predetermined by fixed transition probabilities. MDPs give the agent *choices* - the agent actively decides which action to take, fundamentally changing from passive observation to active control. |\n| **Deep RL** | We use tabular methods with discrete states. Deep RL uses neural networks for large/continuous state spaces. | Our 16-state FrozenLake has a 16\u00d716 transition matrix we can store exactly. Deep RL handles millions of states (images, sensor data) using neural networks to approximate transition dynamics - adding significant complexity. |\n\n## Prerequisites\n- Completed Part 1 (Foundations of RL)\n- Basic linear algebra (matrix multiplication)\n- Basic probability (conditional probability, probability distributions)\n\n## How to Read This Notebook\n1. **Start with the transition matrix section** - Understanding how to read these matrices is crucial\n2. **See the concepts in code** - We build transition matrices for FrozenLake\n3. **Visualize state evolution** - Heatmaps and simulations make the math concrete\n4. **Use checkpoints** - Verify your understanding before moving on\n\nLet's begin!"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment.\n",
    "\n",
    "> **Note:** If you're running this in a fresh environment (like Google Colab or a new virtualenv), uncomment and run the installation cell below first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries (uncomment if needed)\n",
    "# !pip install gymnasium[toy-text] numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to visualize the FrozenLake grid\n",
    "def visualize_frozenlake(env, current_state=None, title=\"FrozenLake Environment\"):\n",
    "    \"\"\"Visualize the FrozenLake grid with the current state highlighted.\"\"\"\n",
    "    desc = env.unwrapped.desc.astype(str)\n",
    "    nrow, ncol = desc.shape\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    colors = {'S': 'lightblue', 'F': 'white', 'H': 'lightcoral', 'G': 'lightgreen'}\n",
    "    \n",
    "    for i in range(nrow):\n",
    "        for j in range(ncol):\n",
    "            cell = desc[i, j]\n",
    "            color = colors.get(cell, 'white')\n",
    "            state_idx = i * ncol + j\n",
    "            if current_state is not None and state_idx == current_state:\n",
    "                rect = plt.Rectangle((j, nrow-1-i), 1, 1, fill=True, \n",
    "                                     facecolor='yellow', edgecolor='black', linewidth=2)\n",
    "            else:\n",
    "                rect = plt.Rectangle((j, nrow-1-i), 1, 1, fill=True,\n",
    "                                     facecolor=color, edgecolor='black', linewidth=1)\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(j + 0.5, nrow - 1 - i + 0.5, cell,\n",
    "                   ha='center', va='center', fontsize=20, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlim(0, ncol)\n",
    "    ax.set_ylim(0, nrow)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    \n",
    "    legend_elements = [\n",
    "        plt.Rectangle((0, 0), 1, 1, facecolor='lightblue', label='S: Start'),\n",
    "        plt.Rectangle((0, 0), 1, 1, facecolor='white', edgecolor='black', label='F: Frozen (safe)'),\n",
    "        plt.Rectangle((0, 0), 1, 1, facecolor='lightcoral', label='H: Hole (game over)'),\n",
    "        plt.Rectangle((0, 0), 1, 1, facecolor='lightgreen', label='G: Goal (reward!)'),\n",
    "        plt.Rectangle((0, 0), 1, 1, facecolor='yellow', edgecolor='black', linewidth=2, label='Current position')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def visualize_value_function(V, title=\"State Value Function V(s)\"):\n",
    "    \"\"\"Visualize the value function as a heatmap on the FrozenLake grid.\"\"\"\n",
    "    V_grid = V.reshape((4, 4))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    \n",
    "    im = sns.heatmap(V_grid, annot=True, fmt=\".3f\", cmap=\"Greens\", \n",
    "                     cbar_kws={'label': 'Value'}, ax=ax,\n",
    "                     linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    labels = [['S', 'F', 'F', 'F'],\n",
    "              ['F', 'H', 'F', 'H'],\n",
    "              ['F', 'F', 'F', 'H'],\n",
    "              ['H', 'F', 'F', 'G']]\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            ax.text(j + 0.5, i + 0.15, labels[i][j], \n",
    "                   ha='center', va='center', fontsize=10, \n",
    "                   color='red' if labels[i][j] == 'H' else 'blue',\n",
    "                   fontweight='bold')\n",
    "    \n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Column')\n",
    "    ax.set_ylabel('Row')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Understanding Transition Matrices (Foundation)\n",
    "\n",
    "Before we dive into Markov Processes and MDPs, let's first understand a fundamental building block: the **transition probability matrix**. This concept appears throughout reinforcement learning, so grasping it now will make everything else much clearer!\n",
    "\n",
    "## What is a Transition Matrix?\n",
    "\n",
    "A **transition matrix** $P$ describes how an agent (or system) moves between states. It's organized as a table:\n",
    "\n",
    "- **Rows** represent the **current state** $s$\n",
    "- **Columns** represent the **next state** $s'$\n",
    "- **Entry** $P_{ss'}$ = probability of going from state $s$ to state $s'$\n",
    "\n",
    "### Example with 3 States\n",
    "\n",
    "Suppose we have 3 states: {0, 1, 2}. The transition matrix looks like:\n",
    "\n",
    "$$P = \\begin{bmatrix}\n",
    "P_{00} & P_{01} & P_{02} \\\\\n",
    "P_{10} & P_{11} & P_{12} \\\\\n",
    "P_{20} & P_{21} & P_{22}\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "P(0 \\to 0) & P(0 \\to 1) & P(0 \\to 2) \\\\\n",
    "P(1 \\to 0) & P(1 \\to 1) & P(1 \\to 2) \\\\\n",
    "P(2 \\to 0) & P(2 \\to 1) & P(2 \\to 2)\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "### How to Read the Matrix\n",
    "\n",
    "**Rule:** To find the probability of going from state $i$ to state $j$, look at **row $i$, column $j$**.\n",
    "\n",
    "- **Row 0** shows all transitions **from** state 0: where can I go from state 0?\n",
    "- **Row 1** shows all transitions **from** state 1: where can I go from state 1?\n",
    "- **Row 2** shows all transitions **from** state 2: where can I go from state 2?\n",
    "\n",
    "### Concrete Example\n",
    "\n",
    "$$P = \\begin{bmatrix}\n",
    "0.5 & 0.3 & 0.2 \\\\\n",
    "0.1 & 0.7 & 0.2 \\\\\n",
    "0.0 & 0.4 & 0.6\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "**Reading this matrix:**\n",
    "\n",
    "**From state 0 (row 0):**\n",
    "- 50% chance to stay in state 0 ($P_{00} = 0.5$)\n",
    "- 30% chance to go to state 1 ($P_{01} = 0.3$)\n",
    "- 20% chance to go to state 2 ($P_{02} = 0.2$)\n",
    "- **Row sum:** $0.5 + 0.3 + 0.2 = 1.0$ \u2713\n",
    "\n",
    "**From state 1 (row 1):**\n",
    "- 10% chance to go to state 0 ($P_{10} = 0.1$)\n",
    "- 70% chance to stay in state 1 ($P_{11} = 0.7$)\n",
    "- 20% chance to go to state 2 ($P_{12} = 0.2$)\n",
    "- **Row sum:** $0.1 + 0.7 + 0.2 = 1.0$ \u2713\n",
    "\n",
    "**From state 2 (row 2):**\n",
    "- 0% chance to go to state 0 ($P_{20} = 0.0$) - impossible!\n",
    "- 40% chance to go to state 1 ($P_{21} = 0.4$)\n",
    "- 60% chance to stay in state 2 ($P_{22} = 0.6$)\n",
    "- **Row sum:** $0.0 + 0.4 + 0.6 = 1.0$ \u2713\n",
    "\n",
    "## Why Must Each Row Sum to 1?\n",
    "\n",
    "Each row represents **all possible next states** from a given current state. Since the agent **must** end up in *some* state at the next time step, the probabilities must sum to 1 (100%).\n",
    "\n",
    "This is called a **stochastic matrix** or **row-stochastic matrix**.\n",
    "\n",
    "## Key Notation\n",
    "\n",
    "You'll see this notation throughout the notebook:\n",
    "\n",
    "- $P_{ss'}$ = probability of transitioning from state $s$ to state $s'$ (read as \"P sub s s-prime\")\n",
    "- $P[S_{t+1} = s' | S_t = s]$ = the same thing in probability notation (\"probability that next state is s-prime given current state is s\")\n",
    "- $s$ = current state (typically the row)\n",
    "- $s'$ = next state (typically the column, the prime ' means \"next\")\n",
    "\n",
    "## FrozenLake Preview\n",
    "\n",
    "For FrozenLake with 16 states, the transition matrix will be **16\u00d716**:\n",
    "- 16 rows (one for each current state)\n",
    "- 16 columns (one for each possible next state)\n",
    "- 256 total entries (though many will be 0 since not all transitions are possible)\n",
    "\n",
    "Now that you understand transition matrices, let's see how they're used in Markov Processes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Markov Processes (Markov Chains)\n",
    "\n",
    "Now that you understand transition matrices, let's see how they're used! A **Markov Process** (also called a Markov Chain) is the simplest model of sequential state transitions.\n",
    "\n",
    "## Definition\n",
    "\n",
    "A **Markov Process** is a tuple $(S, P)$ where:\n",
    "- $S$ is a finite set of states\n",
    "- $P$ is a **state transition probability matrix**: $P_{ss'} = P[S_{t+1} = s' | S_t = s]$\n",
    "\n",
    "**Plain English:** \"The probability of transitioning from state s to state s-prime equals the probability that the next state is s-prime, given that the current state is s.\"\n",
    "\n",
    "**Formula components:**\n",
    "- $P_{ss'}$ = the transition probability from state $s$ to state $s'$ (read as \"P sub s s-prime\")\n",
    "- $P[\\cdot]$ = probability of the event in brackets\n",
    "- $S_{t+1}$ = the state random variable at the next time step\n",
    "- $s'$ = a specific next state value (the prime ' indicates \"next\")\n",
    "- $|$ = \"given that\" (conditional probability notation)\n",
    "- $S_t$ = the state random variable at the current time step\n",
    "- $s$ = a specific current state value\n",
    "\n",
    "The Markov Process describes a random walk through states, where the next state depends **only on the current state** (the Markov property we learned in Notebook 1.1).\n",
    "\n",
    "## Key Properties\n",
    "\n",
    "| Property | Description |\n",
    "|----------|-------------|\n",
    "| **No actions** | The agent doesn't make decisions - transitions happen automatically |\n",
    "| **No rewards** | We only track which states we visit, not how \"good\" they are |\n",
    "| **Memoryless** | Future states depend only on the current state, not history |\n",
    "| **Stochastic** | Transitions are probabilistic. Each row of the matrix $P$ represents all possible transitions from one state, and must sum to 1 (as explained in Section 1) |\n",
    "\n",
    "## FrozenLake as a Markov Process\n",
    "\n",
    "If we take FrozenLake and fix a policy (say, uniform random), the agent no longer makes decisions - it just follows the policy automatically. Since FrozenLake has no rewards in a pure Markov Process view, this gives us a **Markov Process** (we ignore rewards for now).\n",
    "\n",
    "- **States**: The 16 positions on the grid (0-15)\n",
    "- **Transitions**: Determined by the fixed policy + slippery ice dynamics\n",
    "- **Matrix size**: 16\u00d716 (16 states, so 16 rows and 16 columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenLake with Random Policy = Markov Process\n",
      "==================================================\n",
      "\n",
      "States S: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}\n",
      "Number of states |S|: 16\n",
      "\n",
      "With a fixed random policy, the agent doesn't choose -\n",
      "it just follows the policy, creating a Markov Chain.\n"
     ]
    }
   ],
   "source": [
    "# Create FrozenLake environment\n",
    "env = gym.make(\"FrozenLake-v1\", render_mode=\"rgb_array\", is_slippery=True)\n",
    "env.reset(seed=42)\n",
    "\n",
    "print(\"FrozenLake with Random Policy = Markov Process\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nStates S: {{{', '.join(map(str, range(16)))}}}\")\n",
    "print(f\"Number of states |S|: {env.observation_space.n}\")\n",
    "print(\"\\nWith a fixed random policy, the agent doesn't choose -\")\n",
    "print(\"it just follows the policy, creating a Markov Chain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udd0d About the Code Below\n",
    "\n",
    "In the next code cells, we'll use `env.unwrapped.P` to **peek inside** FrozenLake's internal model. This is **instructor-only knowledge** for educational purposes.\n",
    "\n",
    "**Remember: A real RL agent does NOT have access to this information!** \n",
    "\n",
    "The agent would need to learn the transition probabilities and rewards through trial and error by interacting with the environment. We're using `env.unwrapped.P` here to:\n",
    "- Understand the theoretical concepts\n",
    "- Verify our calculations\n",
    "- Visualize the true structure of the MDP\n",
    "\n",
    "In later notebooks, you'll see how agents learn these dynamics without access to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix P (Markov Chain under Random Policy)\n",
      "=======================================================\n",
      "\n",
      "Shape: (16, 16) (16 states \u00d7 16 states)\n",
      "Row sums (should all be 1.0): [1. 1. 1. 1.]... (first 4 shown)\n",
      "\n",
      "Transition probabilities FROM state 0 (Start):\n",
      "  P(0 \u2192 0) = 0.5000\n",
      "  P(0 \u2192 1) = 0.2500\n",
      "  P(0 \u2192 4) = 0.2500\n"
     ]
    }
   ],
   "source": [
    "# Build the transition matrix P for FrozenLake under a uniform random policy\n",
    "def build_markov_chain_matrix(env):\n",
    "    \"\"\"\n",
    "    Build transition matrix P for FrozenLake with uniform random policy.\n",
    "    P[s, s'] = probability of going from state s to state s'\n",
    "    \"\"\"\n",
    "    n_states = env.observation_space.n\n",
    "    n_actions = env.action_space.n\n",
    "    \n",
    "    # Under uniform random policy, each action has probability 1/n_actions\n",
    "    policy_prob = 1.0 / n_actions\n",
    "    \n",
    "    # Initialize transition matrix\n",
    "    P = np.zeros((n_states, n_states))\n",
    "    \n",
    "    # For each state and action, accumulate transition probabilities\n",
    "    for state in range(n_states):\n",
    "        for action in range(n_actions):\n",
    "            # Get transitions for this state-action pair\n",
    "            for prob, next_state, reward, done in env.unwrapped.P[state][action]:\n",
    "                # Weight by policy probability\n",
    "                P[state, next_state] += policy_prob * prob\n",
    "    \n",
    "    return P\n",
    "\n",
    "P_chain = build_markov_chain_matrix(env)\n",
    "\n",
    "print(\"Transition Matrix P (Markov Chain under Random Policy)\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"\\nShape: {P_chain.shape} (16 states \u00d7 16 states)\")\n",
    "print(f\"Row sums (should all be 1.0): {P_chain.sum(axis=1)[:4]}... (first 4 shown)\")\n",
    "print(\"\\nTransition probabilities FROM state 0 (Start):\")\n",
    "for next_s in range(16):\n",
    "    if P_chain[0, next_s] > 0:\n",
    "        print(f\"  P(0 \u2192 {next_s}) = {P_chain[0, next_s]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Question this plot answers:** 'What are the transition probabilities between all states?'\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice: Terminal states (5, 7, 11, 12 = Holes, 15 = Goal) have self-loops\n",
      "(probability 1.0 of staying in the same state).\n"
     ]
    }
   ],
   "source": [
    "# Visualize the transition matrix as a heatmap\n",
    "print(\"**Question this plot answers:** 'What are the transition probabilities between all states?'\\n\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(P_chain, annot=False, cmap='Blues', ax=ax,\n",
    "            xticklabels=range(16), yticklabels=range(16))\n",
    "ax.set_xlabel('Next State s\\'')\n",
    "ax.set_ylabel('Current State s')\n",
    "ax.set_title('Markov Chain Transition Matrix P\\n(FrozenLake with Random Policy)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice: Terminal states (5, 7, 11, 12 = Holes, 15 = Goal) have self-loops\")\n",
    "print(\"(probability 1.0 of staying in the same state).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Transition Matrix Heatmap\n",
    "\n",
    "Let's interpret what this visualization is showing us!\n",
    "\n",
    "### The Diagonal Pattern\n",
    "\n",
    "**Why do we see a clear pattern along the diagonal from top-left to bottom-right?**\n",
    "\n",
    "The **dark blue spots on the diagonal** represent **self-loops** - states transitioning to themselves. Here's why this pattern appears:\n",
    "\n",
    "1. **Terminal states have strong self-loops**:\n",
    "   - **Holes** (states 5, 7, 11, 12) and **Goal** (state 15) are terminal\n",
    "   - Once you reach a terminal state, you stay there forever (probability = 1.0)\n",
    "   - This creates **dark blue spots** at positions (5,5), (7,7), (11,11), (12,12), and (15,15)\n",
    "\n",
    "2. **Non-terminal states can stay in place**:\n",
    "   - Due to slippery ice, even non-terminal states have a chance of staying put\n",
    "   - When the agent tries to move but slips into a wall, it stays in the same state\n",
    "   - Example: State 0 (top-left corner) has ~50% chance of staying at state 0\n",
    "\n",
    "### How to Read This Heatmap\n",
    "\n",
    "**Each row shows where you can go FROM a given state:**\n",
    "\n",
    "- **X-axis (horizontal)**: Next state $s'$ (where you end up)\n",
    "- **Y-axis (vertical)**: Current state $s$ (where you start)\n",
    "- **Color intensity**: Probability of transition\n",
    "  - **Bright/dark blue** = high probability (close to 1.0)\n",
    "  - **Light blue/white** = low probability (close to 0.0)\n",
    "\n",
    "**To find the transition probability from state $i$ to state $j$:**\n",
    "- Look at **row $i$** (current state)\n",
    "- Find **column $j$** (next state)\n",
    "- The color intensity shows $P(s'=j | s=i)$\n",
    "\n",
    "### Specific Observations\n",
    "\n",
    "Let's examine some interesting patterns:\n",
    "\n",
    "**Row 0 (Start state):**\n",
    "- Darkest blue at column 0 (high chance of staying at start due to walls)\n",
    "- Some blue at columns 1 and 4 (can move right or down)\n",
    "- White/light everywhere else (zero probability to distant states - can't teleport!)\n",
    "\n",
    "**Rows 5, 7, 11, 12, 15 (Terminal states):**\n",
    "- Only dark blue at their own diagonal position\n",
    "- White/light everywhere else\n",
    "- These are **absorbing states** with $P(s|s) = 1.0$\n",
    "\n",
    "**Sparse pattern overall:**\n",
    "- Most of the matrix is **white/light blue** (probability \u2248 0)\n",
    "- Only a few bright blue spots in each row\n",
    "- This makes sense: from any state, you can only reach a **small number of nearby states**\n",
    "- The grid structure limits transitions to adjacent cells\n",
    "\n",
    "**Why is most of the matrix white (empty)?**\n",
    "- FrozenLake is a **grid world** where you can only move to adjacent cells\n",
    "- From state 6 (middle of grid), you can't reach state 15 (goal) in one step\n",
    "- The slippery ice means from any non-terminal state, you can reach at most 3-4 different next states\n",
    "- Out of 16 possible next states, only 3-4 have non-zero probability (blue)\n",
    "- The other 12-13 states are impossible to reach in one step (white)\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "This sparse structure (most entries are 0) is common in RL:\n",
    "- **Grid worlds**: Can only reach nearby states\n",
    "- **Board games**: Moves have limited reach\n",
    "- **Robotics**: Physical constraints limit state transitions\n",
    "\n",
    "Algorithms exploit this sparsity for efficiency - we don't need to store or compute the zero entries!\n",
    "\n",
    "> **Visual tip:** Terminal states are easy to spot in the heatmap - they have a single dark blue spot on the diagonal and are white everywhere else.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Trajectories through Markov Chain (starting from state 0)\n",
      "============================================================\n",
      "\n",
      "Episode 1: 0 \u2192 0 \u2192 4 \u2192 5\n",
      "   Outcome: Hole at 5 (4 steps)\n",
      "\n",
      "Episode 2: 0 \u2192 1 \u2192 0 \u2192 0 \u2192 0 \u2192 4 \u2192 5\n",
      "   Outcome: Hole at 5 (7 steps)\n",
      "\n",
      "Episode 3: 0 \u2192 1 \u2192 0 \u2192 4 \u2192 8 \u2192 4 \u2192 0 \u2192 0 \u2192 0 \u2192 1 \u2192 1 \u2192 1 \u2192 2 \u2192 1 \u2192 1 \u2192 1 \u2192 1 \u2192 5\n",
      "   Outcome: Hole at 5 (18 steps)\n",
      "\n",
      "Episode 4: 0 \u2192 0 \u2192 1 \u2192 2 \u2192 1 \u2192 2 \u2192 1 \u2192 0 \u2192 4 \u2192 8 \u2192 12\n",
      "   Outcome: Hole at 12 (11 steps)\n",
      "\n",
      "Episode 5: 0 \u2192 0 \u2192 0 \u2192 1 \u2192 1 \u2192 0 \u2192 0 \u2192 0 \u2192 4 \u2192 4 \u2192 5\n",
      "   Outcome: Hole at 5 (11 steps)\n"
     ]
    }
   ],
   "source": [
    "# Simulate random walks on the Markov Chain\n",
    "def simulate_markov_chain(P, start_state, max_steps=50):\n",
    "    \"\"\"Simulate a trajectory through the Markov Chain.\"\"\"\n",
    "    trajectory = [start_state]\n",
    "    current = start_state\n",
    "    terminal_states = {5, 7, 11, 12, 15}  # Holes and Goal\n",
    "    \n",
    "    for _ in range(max_steps):\n",
    "        if current in terminal_states:\n",
    "            break\n",
    "        # Sample next state according to transition probabilities\n",
    "        next_state = np.random.choice(len(P), p=P[current])\n",
    "        trajectory.append(next_state)\n",
    "        current = next_state\n",
    "    \n",
    "    return trajectory\n",
    "\n",
    "# Simulate several episodes\n",
    "np.random.seed(42)\n",
    "print(\"Sample Trajectories through Markov Chain (starting from state 0)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for episode in range(5):\n",
    "    traj = simulate_markov_chain(P_chain, start_state=0)\n",
    "    final_state = traj[-1]\n",
    "    outcome = \"Goal!\" if final_state == 15 else f\"Hole at {final_state}\" if final_state in {5,7,11,12} else \"Timeout\"\n",
    "    print(f\"\\nEpisode {episode + 1}: {' \u2192 '.join(map(str, traj))}\")\n",
    "    print(f\"   Outcome: {outcome} ({len(traj)} steps)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Checkpoint \u2014 You should now understand:**\n",
    "> - A Markov Process (Markov Chain) is defined by states $S$ and transitions $P$\n",
    "> - With a fixed policy, an MDP becomes a Markov Chain\n",
    "> - The transition matrix $P$ captures all state-to-state probabilities where each row of $P$ sums to 1 (we must go somewhere)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-summary",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Summary and Concept Map\n",
    "\n",
    "Let's visualize the concepts we've learned:\n",
    "\n",
    "```\n",
    "MARKOV CHAINS (MARKOV PROCESSES)\n",
    "=================================\n",
    "\n",
    "Components:\n",
    "  \u2022 States (S): All possible positions/situations\n",
    "  \u2022 Transitions (P): Probability matrix showing state evolution\n",
    "\n",
    "Structure:\n",
    "  State s  \u2500\u2500P(s'|s)\u2500\u2500>  State s'\n",
    "     \u2502                      \u2502\n",
    "     \u2502    (probabilistic)   \u2502\n",
    "     \u2502                      \u2502\n",
    "     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "       Time step t \u2192 t+1\n",
    "\n",
    "Transition Matrix P:\n",
    "  \u250c                              \u2510\n",
    "  \u2502 P(0\u21920)  P(0\u21921)  ...  P(0\u2192n) \u2502  \u2190 From state 0\n",
    "  \u2502 P(1\u21920)  P(1\u21921)  ...  P(1\u2192n) \u2502  \u2190 From state 1\n",
    "  \u2502   ...     ...    ...   ...  \u2502\n",
    "  \u2502 P(n\u21920)  P(n\u21921)  ...  P(n\u2192n) \u2502  \u2190 From state n\n",
    "  \u2514                              \u2518\n",
    "      \u2193       \u2193            \u2193\n",
    "    To 0    To 1         To n\n",
    "\n",
    "Properties:\n",
    "  \u2022 Each row sums to 1.0 (must go somewhere)\n",
    "  \u2022 Markov property: P(s'|s) depends only on s, not history\n",
    "  \u2022 No actions (transitions happen automatically)\n",
    "  \u2022 No rewards (just state evolution)\n",
    "\n",
    "Building Blocks for:\n",
    "  Markov Chain  \u2192  Add Rewards  \u2192  Markov Reward Process (Part 2.2)\n",
    "                \u2192  Add Actions  \u2192  Markov Decision Process (Part 2.3)\n",
    "```\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Transition matrices** encode all state-to-state probabilities as a table\n",
    "- **Row i, column j** gives P(go to state j | currently in state i)\n",
    "- **Each row sums to 1** because we must transition somewhere\n",
    "- **Markov chains** describe random walks through states with no actions or rewards\n",
    "- **With a fixed policy**, any MDP becomes a Markov chain\n",
    "- **Sparse matrices** are common in RL (can only reach nearby states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-exercises",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Your Turn\n",
    "\n",
    "Now it's time to test your understanding with some exercises!\n",
    "\n",
    "## Exercise 1: Understanding Transition Probabilities\n",
    "\n",
    "Look at the transition matrix `P_chain` we computed. Answer this conceptual question:\n",
    "\n",
    "**Question:** Why does state 0 (top-left corner) have a 50% probability of staying in state 0 (P[0,0] = 0.5)?\n",
    "\n",
    "<details>\n",
    "<summary>Click to see hint</summary>\n",
    "\n",
    "Think about:\n",
    "- State 0 is in a corner (walls on two sides)\n",
    "- The agent uses a uniform random policy (all 4 actions equally likely)\n",
    "- The ice is slippery (intended action works 1/3 of the time)\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Click to see answer</summary>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "State 0 is in the top-left corner with walls on the top and left sides.\n",
    "\n",
    "Under a uniform random policy:\n",
    "- 25% of the time: Agent chooses LEFT \u2192 hits wall \u2192 stays at 0\n",
    "- 25% of the time: Agent chooses UP \u2192 hits wall \u2192 stays at 0\n",
    "- 25% of the time: Agent chooses RIGHT \u2192 might go to 1 or slip\n",
    "- 25% of the time: Agent chooses DOWN \u2192 might go to 4 or slip\n",
    "\n",
    "For LEFT and UP actions:\n",
    "- All three possible outcomes (intended direction \u00b1 90\u00b0) hit walls\n",
    "- Result: 100% probability of staying at state 0\n",
    "- Contribution: 0.25 + 0.25 = 0.50\n",
    "\n",
    "For RIGHT and DOWN actions:\n",
    "- Some slip directions can hit the walls\n",
    "- These contribute additional probability to staying at 0\n",
    "\n",
    "**Total: P(0\u21920) = 0.50** (half the time we stay put due to walls)\n",
    "</details>\n",
    "\n",
    "## Exercise 2: Compute Transition Probabilities\n",
    "\n",
    "Write code to verify that **all rows** of the transition matrix sum to 1.0.\n",
    "\n",
    "```python\n",
    "# YOUR CODE HERE\n",
    "# Check that all rows sum to 1.0\n",
    "row_sums = # ...\n",
    "print(f\"All rows sum to 1.0: {# ...}\")\n",
    "print(f\"Min row sum: {# ...}\")\n",
    "print(f\"Max row sum: {# ...}\")\n",
    "```\n",
    "\n",
    "<details>\n",
    "<summary>Click to see answer</summary>\n",
    "\n",
    "```python\n",
    "# Check that all rows sum to 1.0\n",
    "row_sums = P_chain.sum(axis=1)\n",
    "print(f\"All rows sum to 1.0: {np.allclose(row_sums, 1.0)}\")\n",
    "print(f\"Min row sum: {row_sums.min():.10f}\")\n",
    "print(f\"Max row sum: {row_sums.max():.10f}\")\n",
    "\n",
    "# Should output:\n",
    "# All rows sum to 1.0: True\n",
    "# Min row sum: 1.0000000000\n",
    "# Max row sum: 1.0000000000\n",
    "```\n",
    "</details>\n",
    "\n",
    "## Exercise 3 (Optional): Simulate a Markov Chain\n",
    "\n",
    "Modify the `simulate_markov_chain` function to track and return:\n",
    "1. How many times each state was visited\n",
    "2. The empirical transition frequencies (visited_count[s'][s] / visited_count[s])\n",
    "\n",
    "Run 10,000 simulations and compare the empirical frequencies with the true transition matrix `P_chain`.\n",
    "\n",
    "<details>\n",
    "<summary>Click to see hint</summary>\n",
    "\n",
    "```python\n",
    "def simulate_and_track(P, start_state, n_episodes=10000):\n",
    "    visit_counts = np.zeros(len(P))\n",
    "    transition_counts = np.zeros((len(P), len(P)))\n",
    "    \n",
    "    for _ in range(n_episodes):\n",
    "        # Similar to simulate_markov_chain but track visits\n",
    "        # ...\n",
    "    \n",
    "    # Compute empirical transition matrix\n",
    "    empirical_P = transition_counts / visit_counts[:, np.newaxis]\n",
    "    return empirical_P\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n**Congratulations! You've completed Part 2.1 of the RL Tutorial!**\n\nKey takeaways:\n- Transition matrices mathematically describe how states evolve over time\n- Each row of a transition matrix sums to 1 (probabilities must total 100%)\n- Markov processes (Markov chains) are defined by states S and transitions P\n- The Markov property means the future depends only on the present, not the past\n- With a fixed policy, an MDP becomes a Markov chain\n\nNext: 02_2_markov_reward_processes.ipynb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}