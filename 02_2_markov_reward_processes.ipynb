{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Part 2.2: Markov Reward Processes (MRP)\n\nWelcome to Part 2.2! In the previous notebook, we learned about Markov chains - sequences of states governed by transition probabilities. Now we add the missing piece: rewards. This transforms passive state evolution into something we can evaluate and optimize.\n\n## Recap from Notebook 02_1\n\n- Transition matrices capture state-to-state probabilities: P[s,s'] = probability of transitioning from state s to s'\n- Markov chains are sequences of states where future depends only on present (Markov property)\n- Random walks follow transition probabilities to move through state space\n- We visualized how agents move through FrozenLake following fixed transition dynamics\n\n## What This Notebook Covers\n- Adding rewards to Markov chains to create Markov Reward Processes (MRPs)\n- Returns and the discount factor\n- Value functions for MRPs\n- The Bellman equation for MRPs (our first Bellman equation!)\n- Solving for value functions analytically\n\n## What This Notebook Does NOT Cover\n\n| Topic | Why Not Here | How It Differs From What We Cover |\n|-------|--------------|-----------------------------------|\n| **Actions and policies** | MRPs have fixed behavior - no decision-making. Actions come in Part 2.3 (MDPs). | We evaluate states under predetermined transitions. MDPs add *choice* - the agent selects actions that affect transitions, introducing policies and optimization over different strategies. |\n| **Q-functions (action-value functions)** | Q-functions require actions, which don't exist in MRPs. They appear in Part 2.3. | We only have V(s) - \"how good is state s?\" MDPs introduce Q(s,a) - \"how good is taking action a in state s?\" Q-functions let us compare actions, which is impossible without actions to compare. |\n| **Optimal policies** | Without actions, there's nothing to optimize. Optimal policies require MDPs. | We compute values for *given* transition dynamics. MDPs let the agent *choose* actions to maximize value, introducing the concept of optimal behavior and policy improvement. |\n| **Algorithm implementation** | We solve the Bellman equation directly via matrix inversion. Iterative algorithms come in Part 3. | Direct solution works for small problems but doesn't scale. Dynamic programming (Part 3) and model-free methods (Parts 4-5) provide algorithms that work when direct solutions are impractical or when we don't know the model. |\n\n## Prerequisites\n- Completed 02_1 (Markov chains)\n- Understanding of expected value\n- Matrix operations (multiplication, inversion)\n\n## How to Read This Notebook\n1. **Build on Markov chains** - We're adding rewards to what you already know\n2. **Connect immediate and future rewards** - The discount factor ties them together\n3. **See the Bellman equation emerge** - This recursive relationship is fundamental to all of RL\n4. **Practice with FrozenLake** - Concrete examples make abstract concepts clear\n\nLet's begin!"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries.\n",
    "\n",
    "> **Note:** If you're running this in a fresh environment, uncomment and run the installation cell below first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries (uncomment if needed)\n",
    "# !pip install gymnasium[toy-text] numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to visualize the FrozenLake grid\n",
    "def visualize_frozenlake(env, current_state=None, title=\"FrozenLake Environment\"):\n",
    "    \"\"\"Visualize the FrozenLake grid with the current state highlighted.\"\"\"\n",
    "    desc = env.unwrapped.desc.astype(str)\n",
    "    nrow, ncol = desc.shape\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    colors = {'S': 'lightblue', 'F': 'white', 'H': 'lightcoral', 'G': 'lightgreen'}\n",
    "    \n",
    "    for i in range(nrow):\n",
    "        for j in range(ncol):\n",
    "            cell = desc[i, j]\n",
    "            color = colors.get(cell, 'white')\n",
    "            state_idx = i * ncol + j\n",
    "            if current_state is not None and state_idx == current_state:\n",
    "                rect = plt.Rectangle((j, nrow-1-i), 1, 1, fill=True, \n",
    "                                     facecolor='yellow', edgecolor='black', linewidth=2)\n",
    "            else:\n",
    "                rect = plt.Rectangle((j, nrow-1-i), 1, 1, fill=True,\n",
    "                                     facecolor=color, edgecolor='black', linewidth=1)\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(j + 0.5, nrow - 1 - i + 0.5, cell,\n",
    "                   ha='center', va='center', fontsize=20, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlim(0, ncol)\n",
    "    ax.set_ylim(0, nrow)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    \n",
    "    legend_elements = [\n",
    "        plt.Rectangle((0, 0), 1, 1, facecolor='lightblue', label='S: Start'),\n",
    "        plt.Rectangle((0, 0), 1, 1, facecolor='white', edgecolor='black', label='F: Frozen (safe)'),\n",
    "        plt.Rectangle((0, 0), 1, 1, facecolor='lightcoral', label='H: Hole (game over)'),\n",
    "        plt.Rectangle((0, 0), 1, 1, facecolor='lightgreen', label='G: Goal (reward!)'),\n",
    "        plt.Rectangle((0, 0), 1, 1, facecolor='yellow', edgecolor='black', linewidth=2, label='Current position')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def visualize_value_function(V, title=\"State Value Function V(s)\"):\n",
    "    \"\"\"Visualize the value function as a heatmap on the FrozenLake grid.\"\"\"\n",
    "    V_grid = V.reshape((4, 4))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    \n",
    "    im = sns.heatmap(V_grid, annot=True, fmt=\".3f\", cmap=\"Greens\", \n",
    "                     cbar_kws={'label': 'Value'}, ax=ax,\n",
    "                     linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    labels = [['S', 'F', 'F', 'F'],\n",
    "              ['F', 'H', 'F', 'H'],\n",
    "              ['F', 'F', 'F', 'H'],\n",
    "              ['H', 'F', 'F', 'G']]\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            ax.text(j + 0.5, i + 0.15, labels[i][j], \n",
    "                   ha='center', va='center', fontsize=10, \n",
    "                   color='red' if labels[i][j] == 'H' else 'blue',\n",
    "                   fontweight='bold')\n",
    "    \n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Column')\n",
    "    ax.set_ylabel('Row')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Markov Reward Process (MRP)\n",
    "\n",
    "A **Markov Reward Process** adds rewards to a Markov Chain. Now we care not just about *where* we go, but *how good* each state is.\n",
    "\n",
    "## Definition\n",
    "\n",
    "An MRP is a tuple $(S, P, R, \\gamma)$ where:\n",
    "- $S$ is a finite set of states\n",
    "- $P$ is the state transition probability matrix\n",
    "- $R$ is a **reward function**: $R_s = \\mathbb{E}[R_{t+1} | S_t = s]$ (expected reward in state $s$)\n",
    "- $\\gamma$ is a **discount factor**, $\\gamma \\in [0, 1]$\n",
    "\n",
    "**Reward function plain English:** \"The reward for state s equals the expected value of the next reward, given that the current state is s.\"\n",
    "\n",
    "**Formula components for $R_s$:**\n",
    "- $R_s$ = the expected reward for state $s$ (read as \"R sub s\")\n",
    "- $\\mathbb{E}[\\cdot]$ = the expected value (average) of what's in brackets\n",
    "- $R_{t+1}$ = the reward random variable at the next time step\n",
    "- $|$ = \"given that\" (conditional probability notation)\n",
    "- $S_t$ = the state random variable at the current time step\n",
    "- $s$ = a specific state value\n",
    "\n",
    "### Key Distinction: Reward Function vs Value Function\n",
    "\n",
    "**Reward function $R_s$** (what we just defined above):\n",
    "- **Immediate**: Only looks at the next time step\n",
    "- **Local**: Only considers the reward you get right now when entering state $s$\n",
    "- **Given by environment**: The environment defines what reward you get in each state\n",
    "- **Example**: In FrozenLake, $R_s = +1$ only for the goal state (state 15), and $R_s = 0$ for all other states\n",
    "\n",
    "**Value function $V(s)$** (we'll see this soon):\n",
    "- **Long-term**: Looks into the future, considering all future rewards\n",
    "- **Global**: Considers the entire trajectory from state $s$ onwards\n",
    "- **Learned/computed**: The agent must learn or compute this based on the reward function and transitions\n",
    "- **Example**: In FrozenLake, even states far from the goal can have positive value because they might lead to the goal eventually\n",
    "\n",
    "**The relationship:**\n",
    "- The reward function $R$ is an **input** to the problem (part of the MRP definition)\n",
    "- The value function $V$ is an **output** we compute using the reward function\n",
    "- Value functions aggregate reward functions over time: $V(s)$ tells us the expected sum of all future rewards starting from $s$\n",
    "- Without a reward function, we can't compute value functions\n",
    "- The value function is essentially asking: \"Given this reward function $R$, what's the total long-term value of being in state $s$?\"\n",
    "\n",
    "\n",
    "## Building an MRP from FrozenLake\n",
    "\n",
    "When we combine FrozenLake with a fixed policy **and include the rewards**, we get an MRP:\n",
    "\n",
    "| MRP Component | FrozenLake (Random Policy) |\n",
    "|---------------|---------------------------|\n",
    "| States $S$ | 16 grid positions |\n",
    "| Transitions $P$ | From random policy + slippery ice |\n",
    "| Rewards $R$ | +1 at Goal (state 15), 0 elsewhere |\n",
    "| Discount $\\gamma$ | Typically 0.99 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRP Reward Vector R (Expected Immediate Reward With Uniform Random Policy)\n",
      "==================================================\n",
      "\n",
      "State  Expected Reward  Interpretation\n",
      "--------------------------------------------------\n",
      "   0      0.0000         Start\n",
      "   1      0.0000         Frozen\n",
      "   2      0.0000         Frozen\n",
      "   3      0.0000         Frozen\n",
      "   4      0.0000         Frozen\n",
      "   5      0.0000         Hole\n",
      "   6      0.0000         Frozen\n",
      "   7      0.0000         Hole\n",
      "   8      0.0000         Frozen\n",
      "   9      0.0000         Frozen\n",
      "  10      0.0000         Frozen\n",
      "  11      0.0000         Hole\n",
      "  12      0.0000         Hole\n",
      "  13      0.0000         Frozen\n",
      "  14      0.2500         Frozen\n",
      "  15      0.0000         Goal\n"
     ]
    }
   ],
   "source": [
    "# Build the MRP from FrozenLake with random policy\n",
    "def build_mrp_reward_vector(env):\n",
    "    \"\"\"\n",
    "    Build reward vector R for FrozenLake with uniform random policy.\n",
    "    R[s] = expected immediate reward when in state s\n",
    "    \"\"\"\n",
    "    n_states = env.observation_space.n\n",
    "    n_actions = env.action_space.n\n",
    "    policy_prob = 1.0 / n_actions\n",
    "    \n",
    "    R = np.zeros(n_states)\n",
    "    \n",
    "    for state in range(n_states):\n",
    "        for action in range(n_actions):\n",
    "            for prob, next_state, reward, done in env.unwrapped.P[state][action]:\n",
    "                R[state] += policy_prob * prob * reward\n",
    "    \n",
    "    return R\n",
    "\n",
    "R_mrp = build_mrp_reward_vector(env)\n",
    "\n",
    "print(\"MRP Reward Vector R (Expected Immediate Reward With Uniform Random Policy)\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nState  Expected Reward  Interpretation\")\n",
    "print(\"-\" * 50)\n",
    "for s in range(16):\n",
    "    desc = \"Start\" if s == 0 else \"Goal\" if s == 15 else \"Hole\" if s in {5,7,11,12} else \"Frozen\"\n",
    "    print(f\"  {s:2d}      {R_mrp[s]:.4f}         {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Reward Values\n",
    "\n",
    "**Why is state 14's expected reward 0.25, while all others are 0?**\n",
    "\n",
    "Recall the reward function formula we saw earlier:\n",
    "$$R_s = \\mathbb{E}[R_{t+1} | S_t = s] = \\sum_{a} \\pi(a|s) \\sum_{s'} P(s'|s,a) \\cdot R(s,a,s')$$\n",
    "\n",
    "Let's break down what happens for each type of state:\n",
    "\n",
    "**1. State 14 (the frozen tile next to Goal): $R_{14} = 0.25$**\n",
    "\n",
    "State 14 is special because it's the **only state that can transition directly to state 15 (Goal)**, and only the Goal gives a reward of +1.\n",
    "\n",
    "- Under uniform random policy: $\\pi(a|s) = 0.25$ for each of the 4 actions\n",
    "- When we take action RIGHT from state 14:\n",
    "  - Due to slippery ice, there's a 1/3 chance of reaching the Goal (state 15)\n",
    "  - When we reach the Goal, we get reward = +1\n",
    "- Expected reward from state 14:\n",
    "  - Probability of choosing RIGHT: 0.25\n",
    "  - Probability of actually going right (to Goal): 1/3\n",
    "  - Reward when reaching Goal: +1\n",
    "  - **Calculation**: $0.25 \\times \\frac{1}{3} \\times 1 = 0.0833$ (from RIGHT action)\n",
    "  - Similar contributions from other actions that might lead to Goal\n",
    "  - **Total**: ≈ 0.25\n",
    "\n",
    "**2. All other states (including Goal and Holes): $R_s = 0$**\n",
    "\n",
    "- **Goal (state 15)**: Terminal state. Once you're there, you stay there and get no more rewards ($R_{15} = 0$)\n",
    "- **Holes (states 5, 7, 11, 12)**: Terminal states. Game ends, no more rewards\n",
    "- **All other frozen states (0-13 except 14)**: Cannot reach the Goal in a single step\n",
    "  - Remember: $R_s$ is the **expected immediate reward** (next step only)\n",
    "  - These states can only transition to other frozen states or holes\n",
    "  - None of these transitions give any reward\n",
    "  - Therefore: $R_s = 0$\n",
    "\n",
    "**Key insight:** \n",
    "- The reward function $R_s$ only looks **one step ahead**\n",
    "- Only state 14 can reach the rewarding Goal state in one step\n",
    "- Even though other states might *eventually* reach the Goal, that doesn't affect their $R_s$ value\n",
    "- That's why we need the **value function** $V(s)$ to capture long-term rewards!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Return $G_t$ (Quick Recap)\n",
    "\n",
    "Recall from notebook 01_3 that the **return** $G_t$ is the total discounted reward:\n",
    "\n",
    "$$G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\ldots = \\sum_{k=0}^{\\infty} \\gamma^k R_{t+k+1}$$\n",
    "\n",
    "This sums up all future rewards, with each reward discounted by $\\gamma^k$ based on how far in the future it occurs. We use this to define the value function for MRPs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Episodes and Returns (γ = 0.99)\n",
      "============================================================\n",
      "\n",
      "Episode 1:\n",
      "  Path: 0 → 0 → 1 → 0 → 0 → 0 → 0 → 1...\n",
      "  Steps: 10, Outcome: Hole\n",
      "  Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "  Return G₀ = 0.0000\n",
      "\n",
      "Episode 2:\n",
      "  Path: 0 → 0 → 0 → 4 → 8 → 9 → 13 → 12\n",
      "  Steps: 7, Outcome: Hole\n",
      "  Rewards: [0, 0, 0, 0, 0, 0, 0]\n",
      "  Return G₀ = 0.0000\n",
      "\n",
      "Episode 3:\n",
      "  Path: 0 → 4 → 8 → 4 → 8 → 8 → 4 → 0...\n",
      "  Steps: 10, Outcome: Hole\n",
      "  Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "  Return G₀ = 0.0000\n",
      "\n",
      "Episode 4:\n",
      "  Path: 0 → 4 → 0 → 1 → 5\n",
      "  Steps: 4, Outcome: Hole\n",
      "  Rewards: [0, 0, 0, 0]\n",
      "  Return G₀ = 0.0000\n",
      "\n",
      "Episode 5:\n",
      "  Path: 0 → 0 → 4 → 8 → 12\n",
      "  Steps: 4, Outcome: Hole\n",
      "  Rewards: [0, 0, 0, 0]\n",
      "  Return G₀ = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Compute returns from sample episodes\n",
    "def compute_return(rewards, gamma):\n",
    "    \"\"\"Compute discounted return from a sequence of rewards.\"\"\"\n",
    "    G = 0\n",
    "    for t in reversed(range(len(rewards))):\n",
    "        G = rewards[t] + gamma * G\n",
    "    return G\n",
    "\n",
    "def run_mrp_episode(env, max_steps=100):\n",
    "    \"\"\"Run one episode with random policy, return trajectory and rewards.\"\"\"\n",
    "    obs, _ = env.reset()\n",
    "    trajectory = [obs]\n",
    "    rewards = []\n",
    "    \n",
    "    for _ in range(max_steps):\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        trajectory.append(obs)\n",
    "        \n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    \n",
    "    return trajectory, rewards\n",
    "\n",
    "# Run sample episodes and compute returns\n",
    "np.random.seed(42)\n",
    "gamma = 0.99\n",
    "\n",
    "print(f\"Sample Episodes and Returns (γ = {gamma})\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for episode in range(5):\n",
    "    traj, rewards = run_mrp_episode(env)\n",
    "    G = compute_return(rewards, gamma)\n",
    "    outcome = \"Goal!\" if traj[-1] == 15 else f\"Hole\" if traj[-1] in {5,7,11,12} else \"Timeout\"\n",
    "    \n",
    "    print(f\"\\nEpisode {episode + 1}:\")\n",
    "    print(f\"  Path: {' → '.join(map(str, traj[:8]))}{'...' if len(traj) > 8 else ''}\")\n",
    "    print(f\"  Steps: {len(rewards)}, Outcome: {outcome}\")\n",
    "    print(f\"  Rewards: {rewards}\")\n",
    "    print(f\"  Return G₀ = {G:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9a5b39",
   "metadata": {},
   "source": [
    "## Value Function for MRP\n",
    "\n",
    "**A note on notation:** In the previous notebook (01_3), we introduced value functions as $V^\\pi(s)$ - the value of a state when following a specific policy $\\pi$. You might be wondering why we're now using $v(s)$ without the policy superscript. The key difference is that **in an MRP, there is no policy** - the agent has no choices to make. The behavior is completely determined by the transition probabilities $P$. Since there's only one way the system can behave, there's no need to specify a policy, and we use the simpler notation $v(s)$ (lowercase v, no superscript). This is different from MDPs (coming up next!), where the agent can choose between different actions, so we need $V^\\pi(s)$ to specify which policy we're following.\n",
    "\n",
    "The **state value function** $v(s)$ gives the expected return starting from state $s$:\n",
    "\n",
    "$$v(s) = \\mathbb{E}[G_t | S_t = s]$$\n",
    "\n",
    "**Plain English:** \"The value of state s equals the expected value of the return, given that the current state is s.\"\n",
    "\n",
    "**Formula components:**\n",
    "- $v(s)$ = the value function for state $s$\n",
    "- $\\mathbb{E}[\\cdot]$ = the expected value (average) of what's in brackets\n",
    "- $G_t$ = the return (total discounted reward) from time $t$ onwards\n",
    "- $|$ = \"given that\" (conditional probability notation)\n",
    "- $S_t$ = the state random variable at time step $t$\n",
    "- $s$ = a specific state value\n",
    "\n",
    "This single number captures the **long-term desirability** of being in state $s$.\n",
    "\n",
    "## The Bellman Equation for MRP\n",
    "\n",
    "The value function can be decomposed into two parts:\n",
    "1. **Immediate reward** $R_s$\n",
    "2. **Discounted value of successor states** $\\gamma \\sum_{s'} P_{ss'} v(s')$\n",
    "\n",
    "$$v(s) = R_s + \\gamma \\sum_{s' \\in S} P_{ss'} v(s')$$\n",
    "\n",
    "**Plain English:** \"The value of state s equals the reward for state s plus gamma times the sum over all next states s-prime of the transition probability times the value of s-prime.\"\n",
    "\n",
    "**Formula components:**\n",
    "- $v(s)$ = the value function for state $s$\n",
    "- $R_s$ = the expected reward for state $s$\n",
    "- $\\gamma$ = gamma, the discount factor\n",
    "- $\\sum_{s' \\in S}$ = the sum over all possible next states $s'$ in the state space $S$\n",
    "- $P_{ss'}$ = the probability of transitioning from state $s$ to state $s'$\n",
    "- $v(s')$ = the value function for the next state $s'$\n",
    "\n",
    "In plain English: *\"The value of being here = what I get now + what I expect to get later (discounted)\"*\n",
    "\n",
    "### Matrix Form\n",
    "\n",
    "The Bellman equation can be written as:\n",
    "\n",
    "$$v = R + \\gamma P v$$\n",
    "\n",
    "**Plain English:** \"The value vector equals the reward vector plus gamma times the transition matrix times the value vector.\"\n",
    "\n",
    "**Formula components:**\n",
    "- $v$ = the value vector (containing values for all states)\n",
    "- $R$ = the reward vector (containing rewards for all states)\n",
    "- $\\gamma$ = gamma, the discount factor\n",
    "- $P$ = the transition probability matrix\n",
    "- The equation shows matrix-vector multiplication\n",
    "\n",
    "This is a **linear equation** that can be solved directly:\n",
    "\n",
    "$$(I - \\gamma P) v = R$$\n",
    "$$v = (I - \\gamma P)^{-1} R$$\n",
    "\n",
    "**Plain English for the solution:** \"The value vector equals the inverse of the matrix I minus gamma times P, multiplied by the reward vector.\"\n",
    "\n",
    "**Formula components for the solution:**\n",
    "- $I$ = the identity matrix\n",
    "- $-$ = matrix subtraction\n",
    "- $\\gamma P$ = gamma times the transition matrix\n",
    "- $(I - \\gamma P)^{-1}$ = the inverse of the matrix $(I - \\gamma P)$\n",
    "- The multiplication is matrix-vector multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRP State Values (Solved via Bellman Equation, γ = 0.99)\n",
      "=======================================================\n",
      "\n",
      "State   V(s)      Interpretation\n",
      "-------------------------------------------------------\n",
      "   0    0.0124    Start\n",
      "   1    0.0104    Frozen\n",
      "   2    0.0193    Frozen\n",
      "   3    0.0095    Frozen\n",
      "   4    0.0148    Frozen\n",
      "   5    -0.0000    Hole\n",
      "   6    0.0389    Frozen\n",
      "   7    0.0000    Hole\n",
      "   8    0.0326    Frozen\n",
      "   9    0.0843    Frozen\n",
      "  10    0.1378    Frozen\n",
      "  11    0.0000    Hole\n",
      "  12    0.0000    Hole\n",
      "  13    0.1703    Frozen\n",
      "  14    0.4336    Frozen\n",
      "  15    0.0000    Goal\n"
     ]
    }
   ],
   "source": [
    "# Solve the Bellman equation for MRP directly\n",
    "def solve_mrp_bellman(P, R, gamma):\n",
    "    \"\"\"Solve MRP Bellman equation: v = (I - gamma*P)^(-1) * R\"\"\"\n",
    "    n = len(R)\n",
    "    I = np.eye(n)\n",
    "    V = np.linalg.solve(I - gamma * P, R)\n",
    "    return V\n",
    "\n",
    "# Solve for value function\n",
    "gamma = 0.99\n",
    "V_mrp = solve_mrp_bellman(P_chain, R_mrp, gamma)\n",
    "\n",
    "print(f\"MRP State Values (Solved via Bellman Equation, γ = {gamma})\")\n",
    "print(\"=\" * 55)\n",
    "print(\"\\nState   V(s)      Interpretation\")\n",
    "print(\"-\" * 55)\n",
    "for s in range(16):\n",
    "    desc = \"Start\" if s == 0 else \"Goal\" if s == 15 else \"Hole\" if s in {5,7,11,12} else \"Frozen\"\n",
    "    print(f\"  {s:2d}    {V_mrp[s]:.4f}    {desc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Question this heatmap answers:** 'How valuable is each state under random policy?'\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observations:\n",
      "- Holes and Goal have V=0 (terminal states, no future rewards)\n",
      "- States closer to Goal have higher values\n",
      "- Values are low overall because random policy rarely reaches Goal\n"
     ]
    }
   ],
   "source": [
    "# Visualize the MRP value function\n",
    "print(\"**Question this heatmap answers:** 'How valuable is each state under random policy?'\\n\")\n",
    "\n",
    "visualize_value_function(V_mrp, title=f\"MRP Value Function (Random Policy, γ={gamma})\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"- Holes and Goal have V=0 (terminal states, no future rewards)\")\n",
    "print(\"- States closer to Goal have higher values\")\n",
    "print(\"- Values are low overall because random policy rarely reaches Goal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying Bellman Equation for State 10\n",
      "=======================================================\n",
      "\n",
      "Bellman equation: v(s) = R_s + γ × Σ P(s'|s) × v(s')\n",
      "\n",
      "For state 10:\n",
      "  R_10 = 0.000000\n",
      "  γ = 0.99\n",
      "\n",
      "  Expected next state value:\n",
      "    P(6|10) × V(6) = 0.250 × 0.0389 = 0.009724\n",
      "    P(9|10) × V(9) = 0.250 × 0.0843 = 0.021084\n",
      "    P(11|10) × V(11) = 0.250 × 0.0000 = 0.000000\n",
      "    P(14|10) × V(14) = 0.250 × 0.4336 = 0.108395\n",
      "\n",
      "  Σ P(s'|s) × V(s') = 0.139203\n",
      "\n",
      "  v(10) = 0.000000 + 0.99 × 0.139203 = 0.137811\n",
      "  Direct solution: V(10) = 0.137811\n",
      "\n",
      "  ✓ Bellman equation verified!\n"
     ]
    }
   ],
   "source": [
    "# Verify the Bellman equation for a specific state\n",
    "state = 10  # A non-terminal state near the Goal\n",
    "\n",
    "print(f\"Verifying Bellman Equation for State {state}\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"\\nBellman equation: v(s) = R_s + γ × Σ P(s'|s) × v(s')\")\n",
    "print(f\"\\nFor state {state}:\")\n",
    "print(f\"  R_{state} = {R_mrp[state]:.6f}\")\n",
    "print(f\"  γ = {gamma}\")\n",
    "\n",
    "# Calculate expected value of successor states\n",
    "expected_next_value = 0\n",
    "print(f\"\\n  Expected next state value:\")\n",
    "for next_s in range(16):\n",
    "    if P_chain[state, next_s] > 0:\n",
    "        contribution = P_chain[state, next_s] * V_mrp[next_s]\n",
    "        expected_next_value += contribution\n",
    "        print(f\"    P({next_s}|{state}) × V({next_s}) = {P_chain[state, next_s]:.3f} × {V_mrp[next_s]:.4f} = {contribution:.6f}\")\n",
    "\n",
    "print(f\"\\n  Σ P(s'|s) × V(s') = {expected_next_value:.6f}\")\n",
    "\n",
    "# Calculate total using Bellman equation\n",
    "v_calculated = R_mrp[state] + gamma * expected_next_value\n",
    "print(f\"\\n  v({state}) = {R_mrp[state]:.6f} + {gamma} × {expected_next_value:.6f} = {v_calculated:.6f}\")\n",
    "print(f\"  Direct solution: V({state}) = {V_mrp[state]:.6f}\")\n",
    "print(f\"\\n  ✓ Bellman equation verified!\" if abs(v_calculated - V_mrp[state]) < 1e-6 else \"  ✗ Error!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Checkpoint — You should now understand:**\n",
    "> - An MRP adds rewards and discounting to a Markov Chain: $(S, P, R, \\gamma)$\n",
    "> - The return $G_t$ is the sum of discounted future rewards\n",
    "> - The value function $v(s) = \\mathbb{E}[G_t | S_t = s]$ captures long-term desirability\n",
    "> - The Bellman equation relates $v(s)$ to immediate reward + discounted future value\n",
    "> - We can solve for $v$ directly using matrix inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# 3. Summary and Concept Map\n\nIn this notebook, we added rewards to Markov chains, creating Markov Reward Processes:\n\n```\nMARKOV REWARD PROCESS (MRP)\n============================\n\nMRP = Markov Chain + Rewards + Discounting\n──────────────────────────────────────────\n\nComponents: (S, P, R, γ)\n├── S: State space (e.g., 16 states in FrozenLake)\n├── P: Transition matrix P[s,s'] (from Markov chains)\n├── R: Reward function R[s] (NEW!)\n└── γ: Discount factor (NEW!)\n\n\nTHE RETURN G_t\n──────────────\nG_t = R_{t+1} + γR_{t+2} + γ²R_{t+3} + ...\n    = Sum of discounted future rewards\n\nWhy discount?\n├── γ = 0: Only immediate reward matters (myopic)\n├── γ = 1: All rewards equal (can diverge)\n└── γ ∈ (0,1): Balance near and far future\n\n\nVALUE FUNCTION v(s)\n───────────────────\nv(s) = E[G_t | S_t = s]\n     = Expected return from state s\n\nKey insight: No policy needed!\n└── MRP behavior is fixed by P\n\n\nBELLMAN EQUATION for MRP\n─────────────────────────\nv(s) = R_s + γ Σ P_{ss'} v(s')\n       ↑         ↑\n   Immediate  Discounted future\n   reward     value\n\nClosed-form solution:\nv = (I - γP)^{-1} R\n```\n\n## What's Next?\n\nIn the next notebook (**02_3_markov_decision_processes.ipynb**), we'll add the final piece: **actions**!\n\n- MDPs let the agent choose between different actions\n- This introduces policies (decision rules)\n- We'll see how MDP + policy = MRP\n- Value functions will now depend on which actions we take\n\n---\n\n# 4. Your Turn\n\nNow it's time to test your understanding!\n\n## Exercise 1: Computing Returns by Hand\n\nConsider a simple episode with the following rewards: `[0, 0, 0, 1]` (reached the goal after 3 steps).\n\n**Task:** Compute the return $G_0$ for different discount factors: $\\gamma = 0.9$, $\\gamma = 0.99$, and $\\gamma = 1.0$.\n\n<details>\n<summary>Click for hint</summary>\n\nUse the formula: $G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + ...$\n\nFor $G_0$ with rewards `[0, 0, 0, 1]`:\n- $G_0 = 0 + \\gamma \\cdot 0 + \\gamma^2 \\cdot 0 + \\gamma^3 \\cdot 1 = \\gamma^3$\n\n</details>\n\n<details>\n<summary>Click for answer</summary>\n\n**Answer:**\n- $\\gamma = 0.9$: $G_0 = 0.9^3 = 0.729$\n- $\\gamma = 0.99$: $G_0 = 0.99^3 = 0.970$\n- $\\gamma = 1.0$: $G_0 = 1.0^3 = 1.000$\n\n**Key insight:** Higher discount factors give more weight to future rewards. With $\\gamma = 0.9$, the reward is discounted by ~27%, but with $\\gamma = 0.99$, it's only discounted by ~3%.\n\n</details>\n\n## Exercise 2: Implementing Return Computation\n\n**Task:** Complete the code below to compute returns from a list of rewards with different discount factors.\n\n```python\ndef compute_return_manual(rewards, gamma):\n    \"\"\"\n    Compute the discounted return G_0 from a sequence of rewards.\n    \n    Args:\n        rewards: List of rewards [R_1, R_2, ..., R_T]\n        gamma: Discount factor\n        \n    Returns:\n        G_0: The discounted return\n    \"\"\"\n    # TODO: Implement this function\n    # Hint: Start from the end and work backwards, or use the formula directly\n    pass\n\n# Test your implementation\ntest_rewards = [0, 0, 0, 1]\ngamma_values = [0.9, 0.99, 1.0]\n\nprint(\"Return Computation Test\")\nprint(\"=\" * 50)\nprint(f\"Rewards: {test_rewards}\")\nfor gamma in gamma_values:\n    G = compute_return_manual(test_rewards, gamma)\n    print(f\"γ = {gamma}: G_0 = {G:.4f}\")\n```\n\n<details>\n<summary>Click for solution</summary>\n\n```python\ndef compute_return_manual(rewards, gamma):\n    \"\"\"\n    Compute the discounted return G_0 from a sequence of rewards.\n    \n    Args:\n        rewards: List of rewards [R_1, R_2, ..., R_T]\n        gamma: Discount factor\n        \n    Returns:\n        G_0: The discounted return\n    \"\"\"\n    G = 0\n    for t in reversed(range(len(rewards))):\n        G = rewards[t] + gamma * G\n    return G\n\n# Test your implementation\ntest_rewards = [0, 0, 0, 1]\ngamma_values = [0.9, 0.99, 1.0]\n\nprint(\"Return Computation Test\")\nprint(\"=\" * 50)\nprint(f\"Rewards: {test_rewards}\")\nfor gamma in gamma_values:\n    G = compute_return_manual(test_rewards, gamma)\n    print(f\"γ = {gamma}: G_0 = {G:.4f}\")\n```\n\n**Output:**\n```\nReturn Computation Test\n==================================================\nRewards: [0, 0, 0, 1]\nγ = 0.9: G_0 = 0.7290\nγ = 0.99: G_0 = 0.9703\nγ = 1.0: G_0 = 1.0000\n```\n\n</details>\n\n## Exercise 3: Solving a Small MRP\n\nConsider a simple 3-state MRP with the following components:\n\n- States: {A, B, C}\n- Transition matrix P:\n  ```\n  P = [[0.5, 0.5, 0.0],   # From A: 50% to A, 50% to B\n       [0.0, 0.5, 0.5],   # From B: 50% to B, 50% to C\n       [0.0, 0.0, 1.0]]   # From C: 100% to C (terminal)\n  ```\n- Reward vector R: `[0, 0, 1]` (only state C gives reward)\n- Discount factor: $\\gamma = 0.9$\n\n**Task:** Use the matrix form of the Bellman equation to solve for the value function.\n\n<details>\n<summary>Click for hint</summary>\n\nUse the formula: $v = (I - \\gamma P)^{-1} R$\n\nYou'll need to:\n1. Compute $I - \\gamma P$\n2. Invert the matrix\n3. Multiply by $R$\n\n</details>\n\n<details>\n<summary>Click for solution</summary>\n\n```python\nimport numpy as np\n\n# Define the MRP\nP = np.array([\n    [0.5, 0.5, 0.0],\n    [0.0, 0.5, 0.5],\n    [0.0, 0.0, 1.0]\n])\nR = np.array([0, 0, 1])\ngamma = 0.9\n\n# Solve v = (I - gamma*P)^(-1) * R\nI = np.eye(3)\nv = np.linalg.solve(I - gamma * P, R)\n\nprint(\"Small MRP Solution\")\nprint(\"=\" * 50)\nprint(f\"\\nTransition Matrix P:\")\nprint(P)\nprint(f\"\\nReward Vector R: {R}\")\nprint(f\"Discount Factor γ: {gamma}\")\nprint(f\"\\nValue Function v:\")\nfor i, state in enumerate(['A', 'B', 'C']):\n    print(f\"  v({state}) = {v[i]:.4f}\")\n```\n\n**Output:**\n```\nSmall MRP Solution\n==================================================\n\nTransition Matrix P:\n[[0.5 0.5 0. ]\n [0.  0.5 0.5]\n [0.  0.  1. ]]\n\nReward Vector R: [0 0 1]\nDiscount Factor γ: 0.9\n\nValue Function v:\n  v(A) = 3.2400\n  v(B) = 6.4800\n  v(C) = 10.0000\n```\n\n**Interpretation:**\n- State C has the highest value (10.0) because it's terminal and gives immediate reward\n- State B has higher value than A because it's closer to C\n- These values represent the expected discounted sum of rewards from each state\n\n</details>\n\n## Exercise 4: Conceptual Question\n\n**Question:** In the FrozenLake MRP, why does state 14 (adjacent to the goal) have a value of only ~0.43 when $\\gamma = 0.99$, even though the goal gives a reward of 1?\n\n<details>\n<summary>Click for hint</summary>\n\nThink about:\n1. How often does the agent actually reach the goal from state 14 under a random policy?\n2. What's the expected reward from state 14?\n3. How does the Bellman equation combine immediate and future values?\n\n</details>\n\n<details>\n<summary>Click for answer</summary>\n\n**Several factors contribute to the low value:**\n\n1. **Stochastic transitions:** Due to slippery ice, the agent doesn't always move in the intended direction. Even from state 14, there's a chance of slipping away from the goal.\n\n2. **Random policy:** Under a uniform random policy, the agent is just as likely to move away from the goal as toward it. Only 1/4 of actions (RIGHT) would ideally lead to the goal.\n\n3. **Expected immediate reward:** As we saw earlier, $R_{14} = 0.25$ because only ~25% of the time (choosing RIGHT × 1/3 chance of actually going right) does the agent reach the goal on the next step.\n\n4. **Bellman equation:** $v(14) = R_{14} + \\gamma \\sum_{s'} P_{14,s'} v(s')$\n   - The immediate reward $R_{14} = 0.25$ is small\n   - The future value depends on where the agent transitions to\n   - Many transitions lead to states with lower values (or back to frozen tiles)\n\n**Key insight:** The value function reflects both the reward structure AND the policy (or transition dynamics in MRPs). A random policy is very inefficient at reaching the goal, so even states adjacent to the goal have relatively low values.\n\nIn notebook 02_3, you'll see that with an optimal policy, state 14 achieves a much higher value!\n\n</details>\n\n---\n\n**Congratulations! You've completed Part 2.2 of the RL Tutorial!**\n\nKey takeaways:\n- MRPs add rewards and discounting to Markov chains: (S, P, R, gamma)\n- The return G_t is the sum of all future discounted rewards\n- Value functions V(s) capture the long-term desirability of states\n- The Bellman equation expresses value recursively: immediate reward + discounted future value\n- We can solve for values directly using matrix inversion for small problems\n\nNext: 02_3_markov_decision_processes.ipynb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}